{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, we need decide what we want to keep, what we want to forget. \n",
    "# Second, we need decide what we want to add from new input\n",
    "# finally, we need decide what we want to output\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wxp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 3 loss: 186.038167968\n",
      "Epoch 1 completed out of 3 loss: 55.517786257\n",
      "Epoch 2 completed out of 3 loss: 38.8526229598\n",
      "Accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "\n",
    "hm_epochs = 3\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "chunk_size = 28\n",
    "n_chunks = 28\n",
    "run_size =128\n",
    "\n",
    "x = tf.placeholder('float', [None, n_chunks,chunk_size])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size, n_classes])),\n",
    "                      'biases':tf.Variable(tf.random_normal([1,n_classes]))}\n",
    "\n",
    "    \n",
    "    # if x has shape (1,5,5) at the beginning, then tf.transpose(x,[1,0,2]) make x to be (5,1,5)\n",
    "    # then x has 5 arrays of chunks, each contains 5 elements.\n",
    "    # reshape(x,[-1,chunk_size]) remove 1 pair of exra braces.\n",
    "    # tf.split(0,n_chunks,x) split it to a list of 5 chunks\n",
    "    x = tf.transpose(x,[1,0,2])\n",
    "    x = tf.reshape(x,[-1,chunk_size])\n",
    "    x = tf.split(x,n_chunks,0)\n",
    "    \n",
    "    lstm_cell = rnn.BasicLSTMCell(run_size)\n",
    "    outputs, states = rnn.static_rnn(lstm_cell,x,dtype=tf.float32)\n",
    "    \n",
    "    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:mnist.test.images.reshape((-1,n_chunks,chunk_size)), y:mnist.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up\n",
    "num_epochs = 10 # trainning steps\n",
    "total_series_length = 50000 # reshape it to 5 * 10000\n",
    "truncated_backprop_length = 15 # numbers of input for one row per time step\n",
    "state_size = 4\n",
    "num_classes = 2 # output is 0 or 1\n",
    "echo_step = 3 # y lag 3 to x\n",
    "batch_size = 5 # rows of input for one time step\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# unpacking, the RNN will simultaneously be training on different parts in the time-series\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one batchX\n",
    "x[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_6:0' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:1' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:2' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:3' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:4' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:5' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:6' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:7' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:8' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:9' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:10' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:11' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:12' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:13' shape=(5,) dtype=int64>,\n",
       " <tf.Tensor 'unstack_6:14' shape=(5,) dtype=int64>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better explannation\n",
    "a = tf.unstack(x[:, :15],axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(5, 1) dtype=int64>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current input\n",
    "tf.reshape(a[0],[5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "# When a RNN is trained, it is actually treated as a deep neural network with \n",
    "# reoccurring weights in every layer. These layers will not be unrolled to the beginning of time, \n",
    "# that would be too computationally expensive, and are therefore truncated at a limited number of \n",
    "# time-steps, and that is truncated_backprop_length\n",
    "current_state = init_state\n",
    "states_series = []\n",
    "\n",
    "for current_input in inputs_series:\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "     # Increasing number of columns\n",
    "    input_and_state_concatenated = tf.concat(axis=1, values=[current_input, current_state]) \n",
    "     # Broadcasted addition\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b) \n",
    "    states_series.append(next_state)\n",
    "    current_state = next_state\n",
    "    \n",
    "# truncated_backprop_length need to be significantly larger than the time dependencies (three steps in our case)\n",
    "\n",
    "\n",
    "#####  simplify code!\n",
    "# Unpack columns\n",
    "\n",
    "#inputs_series = tf.split(1, truncated_backprop_length, batchX_placeholder)\n",
    "#labels_series = tf.unpack(batchY_placeholder, axis=1)\n",
    "# Forward passes\n",
    "#cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "#states_series, current_state = tf.nn.rnn(cell, inputs_series, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculating the loss\n",
    "#Broadcasted addition\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] \n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the trainning process\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26a0c200278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.793846\n",
      "Step 100 Loss 0.0607578\n",
      "Step 200 Loss 0.00631502\n",
      "Step 300 Loss 0.00358661\n",
      "Step 400 Loss 0.00262082\n",
      "Step 500 Loss 0.00195743\n",
      "Step 600 Loss 0.00159739\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.147204\n",
      "Step 100 Loss 0.0012323\n",
      "Step 200 Loss 0.00105019\n",
      "Step 300 Loss 0.000930663\n",
      "Step 400 Loss 0.000737937\n",
      "Step 500 Loss 0.000657555\n",
      "Step 600 Loss 0.00069325\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.166215\n",
      "Step 100 Loss 0.0011348\n",
      "Step 200 Loss 0.000972635\n",
      "Step 300 Loss 0.000843332\n",
      "Step 400 Loss 0.000832252\n",
      "Step 500 Loss 0.000697893\n",
      "Step 600 Loss 0.000608702\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.219808\n",
      "Step 100 Loss 0.000565318\n",
      "Step 200 Loss 0.000605154\n",
      "Step 300 Loss 0.000534327\n",
      "Step 400 Loss 0.000465908\n",
      "Step 500 Loss 0.000426395\n",
      "Step 600 Loss 0.00041094\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.254411\n",
      "Step 100 Loss 0.000420033\n",
      "Step 200 Loss 0.000343719\n",
      "Step 300 Loss 0.000345017\n",
      "Step 400 Loss 0.000384078\n",
      "Step 500 Loss 0.000348114\n",
      "Step 600 Loss 0.000339532\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.168572\n",
      "Step 100 Loss 0.000406926\n",
      "Step 200 Loss 0.000359507\n",
      "Step 300 Loss 0.000362682\n",
      "Step 400 Loss 0.000320439\n",
      "Step 500 Loss 0.000302516\n",
      "Step 600 Loss 0.000313652\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.377981\n",
      "Step 100 Loss 0.000235514\n",
      "Step 200 Loss 0.000239661\n",
      "Step 300 Loss 0.000237249\n",
      "Step 400 Loss 0.000216104\n",
      "Step 500 Loss 0.000234735\n",
      "Step 600 Loss 0.000230943\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.209199\n",
      "Step 100 Loss 0.000253945\n",
      "Step 200 Loss 0.000231506\n",
      "Step 300 Loss 0.000233668\n",
      "Step 400 Loss 0.000193147\n",
      "Step 500 Loss 0.000200341\n",
      "Step 600 Loss 0.000192904\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.15199\n",
      "Step 100 Loss 0.000190528\n",
      "Step 200 Loss 0.000202891\n",
      "Step 300 Loss 0.000185276\n",
      "Step 400 Loss 0.000190656\n",
      "Step 500 Loss 0.000186517\n",
      "Step 600 Loss 0.000172386\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.340039\n",
      "Step 100 Loss 0.000172035\n",
      "Step 200 Loss 0.000157318\n",
      "Step 300 Loss 0.000165133\n",
      "Step 400 Loss 0.000147069\n",
      "Step 500 Loss 0.000156881\n",
      "Step 600 Loss 0.000151139\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26a0bfc3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running a training session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
